import requests
import csv
import argparse
from datetime import datetime
from collections import defaultdict

# Mapping of tags to perspectives and categories (expand as needed)
PERSPECTIVES = {
    "SonarSource": ["sql-injection", "code-injection", "xss", "xxe", "path-traversal", "rce"],
    "OWASP Top 10 2021": ["owasp:a1", "owasp:a2", "owasp:a3", "owasp:a4", "owasp:a5", "owasp:a6", "owasp:a7", "owasp:a8", "owasp:a9", "owasp:a10"],
    "OWASP ASVS v4.0": ["owasp:authentication", "owasp:config", "owasp:file", "owasp:trace", "owasp:permission"],
    "CWE Top 25 2023": ["cwe:787", "cwe:79", "cwe:89", "cwe:416", "cwe:78"],
}

# Grade thresholds based on issue counts
GRADE_THRESHOLDS = {
    "A": 0,
    "B": 1,
    "C": 3,
    "D": 5,
    "E": 10,
}

def determine_grade(count):
    for grade, threshold in GRADE_THRESHOLDS.items():
        if count <= threshold:
            return grade
    return "E"

def get_issues(base_url, project_key, token=None):
    headers = {"Authorization": f"Bearer {token}"} if token else {}
    issues = []
    page = 1
    page_size = 500

    while True:
        params = {
            "componentKeys": project_key,
            "ps": page_size,
            "p": page,
            "additionalFields": "_all"
        }
        r = requests.get(f"{base_url}/api/issues/search", headers=headers, params=params)
        r.raise_for_status()
        data = r.json()
        issues.extend(data["issues"])
        if page * page_size >= data["total"]:
            break
        page += 1

    return issues

def get_hotspots(base_url, project_key, token=None):
    headers = {"Authorization": f"Bearer {token}"} if token else {}
    hotspots = []
    page = 1
    page_size = 500

    while True:
        params = {
            "projectKey": project_key,
            "ps": page_size,
            "p": page,
        }
        r = requests.get(f"{base_url}/api/hotspots/search", headers=headers, params=params)
        r.raise_for_status()
        data = r.json()
        hotspots.extend(data["hotspots"])
        if page * page_size >= data["paging"]["total"]:
            break
        page += 1

    return hotspots

def categorize_by_perspective(issues, hotspots):
    result = defaultdict(lambda: defaultdict(lambda: {"vulns": 0, "hotspots": 0}))
    for issue in issues:
        tags = issue.get("tags", [])
        for perspective, tag_list in PERSPECTIVES.items():
            for tag in tag_list:
                if tag in tags:
                    result[perspective][tag]["vulns"] += 1

    for hs in hotspots:
        tags = hs.get("tags", [])
        for perspective, tag_list in PERSPECTIVES.items():
            for tag in tag_list:
                if tag in tags:
                    result[perspective][tag]["hotspots"] += 1

    return result

def write_report(output_file, project_name, branch, issues, hotspots, categorized_data):
    now = datetime.now().strftime("%Y-%m-%d %H:%M")

    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)

        # Header section
        writer.writerow(["Report date:", now])
        writer.writerow(["Project Name", project_name, "", "", "Branch", branch])
        writer.writerow([])

        # Overall Code Summary (static grades for now)
        writer.writerow(["Overall Code", "Security Rating", "E"])
        writer.writerow(["", "Security Hotspot Review", "E"])
        writer.writerow([])

        # New Code Summary (placeholder grades)
        writer.writerow(["New Code", "Security Rating", "A"])
        writer.writerow(["", "Security Hotspot Review", "A"])
        writer.writerow([])

        # Metadata
        writer.writerow(["Generated by SonarQube", "Simulated CSV Export"])
        writer.writerow([])

        # Perspective breakdown tables
        for perspective, categories in categorized_data.items():
            writer.writerow([f"{perspective} Perspective"])
            writer.writerow(["Category", "Vulnerability Count", "Grade", "Hotspot Count", "Grade"])
            for category, data in categories.items():
                vuln_grade = determine_grade(data["vulns"])
                hs_grade = determine_grade(data["hotspots"])
                writer.writerow([category, data["vulns"], vuln_grade, data["hotspots"], hs_grade])
            writer.writerow([])

    print(f"Report written to {output_file}")

def main():
    parser = argparse.ArgumentParser(description="Generate SonarQube-style security report as CSV.")
    parser.add_argument("--base-url", required=True, help="SonarQube server URL (e.g., http://localhost:9000)")
    parser.add_argument("--project", required=True, help="SonarQube project key")
    parser.add_argument("--token", required=True, help="SonarQube API token")
    parser.add_argument("--output", required=True, help="Output CSV filename (e.g., report.csv)")

    args = parser.parse_args()

    issues = get_issues(args.base_url, args.project, args.token)
    hotspots = get_hotspots(args.base_url, args.project, args.token)

    categorized = categorize_by_perspective(issues, hotspots)
    write_report(args.output, args.project, "main", issues, hotspots, categorized)

if __name__ == "__main__":
    main()